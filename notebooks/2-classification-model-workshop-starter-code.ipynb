{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Workshop: Analyzing bank marketing data with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Your client has given you a dataset and has asked you to build a model to:\n",
    "1. predict whether a given customer is likely to purchase a bank term deposit.\n",
    "2. analyze the factors that make customer more likely (or less likely) to purchase a bank term deposit\n",
    "\n",
    "Build this model by going through the process of tackling classification problems:\n",
    "1. Load and explore data\n",
    "2. Preprocess / clean data\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "5. Use the model (for prediction and interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataset's [README](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing), we know that the data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y). For more info on the dataset, please see the dataset's [README](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/bank-marketing-data/bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the top n rows by calling df.head(n)\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see summary statistics by calling df.describe()\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Clean and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because data cleaning and working with pandas warrants a workshop in itself, the following cells have done the clean up for you. There are plenty of pandas tutorials out there that you can follow to learn more about data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with unknown values\n",
    "for column in df.columns:\n",
    "    if (df[column].dtype == object): \n",
    "        df = df[df[column] != 'unknown'] ## remove rows with unknown\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string data to numerical data so that scikitlearn can understand it\n",
    "cols_to_transform = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "                    'poutcome', 'y']\n",
    "df_with_dummies = pd.get_dummies(df, columns = cols_to_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the redundant 'y_no' column generated by .get_dummies()\n",
    "df = df_with_dummies.drop('y_no', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pandas dataframe into 2 matrices for the model's consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != 'y_yes'].values\n",
    "y = df.iloc[:, df.columns == 'y_yes'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try printing the following commands to get a sense of what X and y actually are:\n",
    "# X.shape, y.shape\n",
    "# X[0], y[0]\n",
    "# X[any_random_integer], y[any_random_integer]\n",
    "# X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn's train_test_split method to split the data into train and test set\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LogisticRegression class from sklearn.linear_model\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the .fit(x_train, y_train) method\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation method 1: `.score(X, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model's performance using the .score() method\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: is 90% accuracy good? Not really... if I had a model that just always predicted y=0, it would be correct 88.7% of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['y_yes'].value_counts())\n",
    "print('Accuracy of a model that always predicted y = 0:')\n",
    "print(36548.0/(36548 + 4640))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation method 2: `.confusion_matrix(expected, predicted)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using metrics.confusion_matrix(y_true, y_predicted)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices are in the following format:\n",
    "    \n",
    "```\n",
    "[[ true negatives,  false positives ]\n",
    " [ false negatives, true positives  ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the rest of this cell and execute it\n",
    "\n",
    "# tn, fp, fn, tp = metrics.confusion_matrix(expected, predicted).ravel()\n",
    "# tn, fp, fn, tp\n",
    "# print(\"=== negatives ===\")\n",
    "# print(\"true negatives: {}\".format(tn))\n",
    "# print(\"false positives: {}\".format(fp))\n",
    "# print()\n",
    "# print(\"=== positives ===\")\n",
    "# print(\"false negatives: {}\".format(fn))\n",
    "# print(\"true positives: {}\".format(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation method 3: `.classification_report(expected, predicted)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using .classification_report(y_true, y_predicted)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2: Train and evaluate the model again with a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank-marketing-data/bank-additional-one-hot-encoded.csv')\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = df[df['y'] == 0]\n",
    "positives = df[df['y'] == 1]\n",
    "negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(positives)\n",
    "sliced_negatives = negatives.head(number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([sliced_negatives, positives])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != 'y'].values\n",
    "y = df.iloc[:, df.columns == 'y'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model \n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "expected_2 = y\n",
    "predicted_2 = model_2.predict(X)\n",
    "report = metrics.classification_report(expected_2, predicted_2)\n",
    "\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the model to predict outcomes based on fresh/unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load new data from '../data/bank-marketing-data/bank-unseen-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen = pd.read_csv('../data/bank-marketing-data/bank-unseen-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data again with df.head(). Notice that there's no 'y' column at the end\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our pandas dataframe to a matrix, so that the model can consume it\n",
    "X_unseen = df_new.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your model to predict the y value (i.e. 0 or 1) of the new data (hint: model.predict()`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your model to predict the probabilities of y being 0 or 1 (hint: model.predict_proba()`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: interpreting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.plot(model.coef_.T, 'o', label=\"logisticregression model (C=1)\")\n",
    "plt.xticks(range(X.shape[1]), df.columns, rotation=90)\n",
    "plt.title(\"Coefficients of logistic_regression_with_threshold model\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.xlabel(\"X variables\")\n",
    "plt.legend()\n",
    "\n",
    "# Note: if you get any errors here saying model is not defined, simply replace 'model' in the second line of this box with the name of your model variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we can interpret coefficients as probabilities, we need to do a little math to calculate the odds ratio\n",
    "# and the probability\n",
    "logodds = model.intercept_ + model.coef_[0] * 2\n",
    "odds = np.exp(logodds)\n",
    "probabilities = odds/(1 + odds)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_x_vars = len(df.columns) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.bar(range(0, number_of_x_vars), probabilities)\n",
    "plt.title(\"Probabilities of outcome where y=1 given a unit change in X\")\n",
    "plt.xlabel(\"X variables\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.axhline(y=0.5, hold=None, alpha=0.5)\n",
    "plt.xticks(range(X.shape[1]), df.columns, rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to interpret the chart \n",
    "\n",
    "We can interpret the chart above as such: Given a unit increase in X, the user is predicted to be \\__% more likely to purchase a bank term deposit (i.e. y=1)\n",
    "\n",
    "For example, given a unit increase in employment variation rate (the first positive blip in the chart), the user is predicted to be 16% more likely to purchase a bank term deposit\n",
    "\n",
    "#### Based on this chart, we can observe the following: \n",
    "    \n",
    "Attributes that have a positive effect on the outcome:\n",
    "- contact_cellular\n",
    "- month_august\n",
    "- month_oct\n",
    "- day_of_week_fri\n",
    "\n",
    "Attributes that have a negative effect on the outcome:\n",
    "- emp.var.rate\n",
    "- cons.price.index\n",
    "- cons.conf.index\n",
    "- euribor3m\n",
    "- education_basic.4y\n",
    "- contact_telephone\n",
    "- month_may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meetup-1-classification",
   "language": "python",
   "name": "meetup-1-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
